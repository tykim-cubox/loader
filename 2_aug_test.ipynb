{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiteam/miniconda3/envs/loader/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "import kornia as K\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from set_loader import CustomDataset, CustomAlbDataset, CustomKorDataset\n",
    "\n",
    "import cv2\n",
    "\n",
    "cv2.setNumThreads(0)\n",
    "cv2.ocl.setUseOpenCL(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 1.0\n",
    "albumentations_transform = A.Compose([\n",
    "    A.RandomCrop(256, 256, p=p),\n",
    "    A.ColorJitter(0.2, 0.2, 0.2, 0.125, p=p),\n",
    "    A.GaussianBlur(3, (0.1, 3.0), p=p),\n",
    "    A.Rotate((-10, 10), p=p),\n",
    "    A.HorizontalFlip(p=p),\n",
    "    A.VerticalFlip(p=p),\n",
    "    A.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5), p=p),\n",
    "    A.pytorch.ToTensorV2(),\n",
    "])\n",
    "kornia_transform = nn.Sequential(\n",
    "    K.augmentation.RandomCrop((256, 256), p=p),\n",
    "    K.augmentation.ColorJitter(0.2, 0.2, 0.2, 0.125, p=p),\n",
    "    K.augmentation.RandomGaussianBlur((3, 3), (0.1, 3.0), p=p),\n",
    "    K.augmentation.RandomRotation([-10, 10], p=p),\n",
    "    K.augmentation.RandomHorizontalFlip(p=p),\n",
    "    K.augmentation.RandomVerticalFlip(p=p),\n",
    "    K.augmentation.Normalize(torch.Tensor([0.5, 0.5, 0.5])*255, torch.Tensor([0.5, 0.5, 0.5])*255, p=p),\n",
    ")\n",
    "\n",
    "\n",
    "torchvision_transform = T.Compose([\n",
    "    T.RandomCrop([256, 256]),\n",
    "    T.ColorJitter(0.2, 0.2, 0.2, 0.125),  #Randomly change the brightness, contrast, saturation and hue of an image.\n",
    "    T.GaussianBlur(3, (0.1, 3.0)),\n",
    "    T.RandomRotation([-10, 10], T.InterpolationMode.BILINEAR),\n",
    "    T.RandomHorizontalFlip(p=p),\n",
    "    T.RandomVerticalFlip(p=p),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AFHQ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchivison - PIL loader\n",
    "\n",
    "root_path = '/home/aiteam/tykim/dataset/afhq/train'\n",
    "custom_ds = CustomDataset(root_path, loader_type='pil', transform=torchvision_transform)\n",
    "dataloader = DataLoader(custom_ds, batch_size=128, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29.005223035812378] sec\n",
      "[28.97568106651306] sec\n",
      "[28.89587140083313] sec\n",
      "[29.200836658477783] sec\n",
      "[28.76229977607727] sec\n",
      "[28.331727743148804] sec\n",
      "[28.6800274848938] sec\n",
      "[28.654899835586548] sec\n",
      "[29.075637817382812] sec\n",
      "28.8 s ± 83.9 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "simple_load_times = []\n",
    "start_time = time.time()\n",
    "for image, label in dataloader:\n",
    "    image = image.cuda()\n",
    "    label = label.cuda()\n",
    "    pass\n",
    "jpeg4py_alb_time = time.time() - start_time\n",
    "simple_load_times.append(jpeg4py_alb_time)\n",
    "print(str(simple_load_times) + ' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jpeg4py + albumentation \n",
    "root_path = '/home/aiteam/tykim/dataset/afhq/train'\n",
    "custom_ds = CustomAlbDataset(root_path, loader_type='jpeg4py', transform=albumentations_transform)\n",
    "dataloader = DataLoader(custom_ds, batch_size=128, shuffle=False, num_workers=8)\n",
    "# custom_ds.transform(image=np.random.randn(512, 512,3).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n",
      "[1.623840093612671] sec\n",
      "1.62 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "simple_load_times = []\n",
    "start_time = time.time()\n",
    "for image, label in dataloader:\n",
    "    image = image.cuda()\n",
    "    label = label.cuda()\n",
    "    pass\n",
    "jpeg4py_alb_time = time.time() - start_time\n",
    "simple_load_times.append(jpeg4py_alb_time)\n",
    "print(str(simple_load_times) + ' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JPEG4PY > PIL > torchivision\n",
    "root_path = '/home/aiteam/tykim/dataset/afhq/train'\n",
    "custom_ds = CustomDataset(root_path, loader_type='jp4pil', transform=torchvision_transform)\n",
    "dataloader = DataLoader(custom_ds, batch_size=128, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32.16102433204651] sec\n",
      "[51.36891031265259] sec\n",
      "[28.907237768173218] sec\n",
      "[43.50913190841675] sec\n",
      "[29.794763326644897] sec\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "simple_load_times = []\n",
    "start_time = time.time()\n",
    "for image, label in dataloader:\n",
    "    image = image.cuda()\n",
    "    label = label.cuda()\n",
    "    pass\n",
    "jp4pil_tv_time = time.time() - start_time\n",
    "simple_load_times.append(jp4pil_tv_time)\n",
    "print(str(simple_load_times) + ' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jpeg4py + kornia-cpu\n",
    "root_path = '/home/aiteam/tykim/dataset/afhq/train'\n",
    "custom_ds = CustomKorDataset(root_path, loader_type='jpeg4py', transform=kornia_transform)\n",
    "dataloader = DataLoader(custom_ds, batch_size=128, shuffle=False, num_workers=8)\n",
    "# custom_ds.transform(image=np.random.randn(512, 512,3).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42.58431816101074] sec\n",
      "[40.74731254577637] sec\n",
      "[40.477243423461914] sec\n",
      "[40.83574032783508] sec\n",
      "[40.696980237960815] sec\n",
      "[40.93867015838623] sec\n",
      "[40.643062114715576] sec\n",
      "[40.99645209312439] sec\n",
      "[40.961018323898315] sec\n",
      "41 s ± 201 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "simple_load_times = []\n",
    "start_time = time.time()\n",
    "for image, label in dataloader:\n",
    "    image = image.cuda()\n",
    "    label = label.cuda()\n",
    "    pass\n",
    "jpeg4py_kornia_time = time.time() - start_time\n",
    "simple_load_times.append(jpeg4py_kornia_time)\n",
    "print(str(simple_load_times) + ' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DALI \n",
    "from nvidia.dali.pipeline import pipeline_def\n",
    "import nvidia.dali.types as types\n",
    "import nvidia.dali.fn as fn\n",
    "from nvidia.dali.plugin.pytorch import DALIGenericIterator\n",
    "\n",
    "root_path = '/home/aiteam/tykim/dataset/afhq/train'\n",
    "\n",
    "@pipeline_def(batch_size=128, num_threads=8, device_id=0)\n",
    "def get_dali_pipeline(data_dir, dali_cpu=False, crop=256):\n",
    "  dali_device = 'cpu' if dali_cpu else 'gpu'\n",
    "  decoder_device = 'cpu' if dali_cpu else 'mixed'\n",
    "  # w, h = int(crop * 120), int(crop * 400)\n",
    "  # imagebytes = w * h * 3 * 4\n",
    "  \n",
    "  img_files, labels = fn.readers.file(file_root=data_dir, random_shuffle=False, name=\"Reader\")\n",
    "  \n",
    "  # Load and Crop\n",
    "  # 이미지 사이즈 힌트\n",
    "  preallocate_width_hint = 512 if decoder_device == 'mixed' else 0\n",
    "  preallocate_height_hint = 512 if decoder_device == 'mixed' else 0\n",
    "  \n",
    "  # images = fn.decoders.image(img_files, device=\"mixed\")\n",
    "  # Decode and Random Crop\n",
    "  images = fn.decoders.image_random_crop(img_files, device=decoder_device, preallocate_width_hint=preallocate_width_hint,\n",
    "                                         preallocate_height_hint=preallocate_height_hint,\n",
    "                                         output_type=types.RGB, random_aspect_ratio=[0.8, 1.25], random_area=[0.1, 1.0])\n",
    "  \n",
    "  # Resize\n",
    "  images = fn.resize(images,device=dali_device,resize_x=crop, resize_y=crop,interp_type=types.INTERP_TRIANGULAR)\n",
    "  # Jitter \n",
    "  images = fn.color_twist(images, brightness=0.2, contrast=0.2, saturation=0.2, hue=0.125)\n",
    "  # GaussianBlur\n",
    "  images = fn.gaussian_blur(images, device = dali_device, # bytes_per_sample_hint = imagebytes, \n",
    "                   sigma = fn.random.uniform(range = (0.1, 3.0)), window_size = 3)\n",
    "  # # Random Rotation\n",
    "  images = fn.rotate(images, device=dali_device, angle=fn.random.uniform(range=(-10, 10)), keep_size=True) \n",
    "  # Horizontal F\n",
    "  images = fn.flip(images, device=dali_device, horizontal=1)\n",
    "  # Vertical F\n",
    "  images = fn.flip(images, device=dali_device, horizontal=0)\n",
    "  # Normalization\n",
    "  images = fn.crop_mirror_normalize(images, device=dali_device,\n",
    "                                    dtype=types.FLOAT,\n",
    "                                    mean = [0.5023*255, 0.4599*255, 0.3993*255],\n",
    "                                    std = [0.2553*255, 0.2457*255, 0.2503*255])\n",
    "  return images, labels.gpu()\n",
    "\n",
    "pipe = get_dali_pipeline(data_dir=root_path)\n",
    "pipe.build()\n",
    "\n",
    "dataloader = DALIGenericIterator(pipe, ['data', 'label'],reader_name='Reader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2623844146728516] sec\n",
      "[1.219261646270752] sec\n",
      "[1.2167339324951172] sec\n",
      "[1.2073204517364502] sec\n",
      "[1.2053849697113037] sec\n",
      "[1.2156667709350586] sec\n",
      "[1.2006504535675049] sec\n",
      "[1.2037441730499268] sec\n",
      "[1.209874153137207] sec\n",
      "1.22 s ± 12.2 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "simple_load_times = []\n",
    "start_time = time.time()\n",
    "for i, data in enumerate(dataloader):\n",
    "  x, y = data[0]['data'], data[0]['label']  \n",
    "\n",
    "dali_time = time.time() - start_time\n",
    "simple_load_times.append(dali_time)\n",
    "print(str(simple_load_times) + ' sec') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFCV - JPEG 100 % quality\n",
    "\n",
    "from ffcv.writer import DatasetWriter\n",
    "from ffcv.fields import IntField, RGBImageField\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from ffcv.fields.decoders import IntDecoder, SimpleRGBImageDecoder, RandomResizedCropRGBImageDecoder\n",
    "from ffcv.loader import Loader, OrderOption\n",
    "from ffcv.transforms import ToDevice, ToTensor, ToTorchImage, NormalizeImage, RandomHorizontalFlip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "beton_path = '/home/aiteam/tykim/scratch/data_loaders/afhq_io_test.beton'\n",
    "\n",
    "# Random resized crop\n",
    "decoder = RandomResizedCropRGBImageDecoder(output_size=(256, 256))# SimpleRGBImageDecoder()\n",
    "mean = np.array([0.5023, 0.4599, 0.3993]) * 255\n",
    "std = np.array([0.2553, 0.2457, 0.2503]) * 255\n",
    "# Data decoding and augmentation\n",
    "image_pipeline = [decoder,  RandomHorizontalFlip(flip_prob=1.0),\n",
    "                  ToTensor(), ToTorchImage(), ToDevice('cuda:0', non_blocking=True),]\n",
    "                  #NormalizeImage(mean, std)] #Cutout(),\n",
    "label_pipeline = [IntDecoder(), ToTensor(), ToDevice('cuda:0')]\n",
    "\n",
    "# Pipeline for each data field\n",
    "pipelines = {\n",
    "    'image': image_pipeline,\n",
    "    'label': label_pipeline\n",
    "}\n",
    "\n",
    "# Replaces PyTorch data loader (`torch.utils.data.Dataloader`)\n",
    "loader = Loader(beton_path, batch_size=128, num_workers=8,\n",
    "                order=OrderOption.RANDOM, pipelines=pipelines, os_cache=True)\n",
    "\n",
    "\n",
    "kornia_transform_ffcv = nn.Sequential(\n",
    "    K.augmentation.ColorJitter(0.2, 0.2, 0.2, 0.125, p=1.0),\n",
    "    K.augmentation.RandomGaussianBlur((3, 3), (0.1, 3.0), p=1.0),\n",
    "    K.augmentation.RandomRotation([-10, 10], p=1.0),\n",
    "    K.augmentation.RandomVerticalFlip(p=1.0),\n",
    "    K.augmentation.Normalize(torch.tensor([0.5023*255, 0.4599*255, 0.3993*255]),\n",
    "                             torch.tensor([0.2553*255, 0.2457*255, 0.2503*255]), p=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.15502142906189] sec\n",
      "[3.9004931449890137] sec\n",
      "[3.6862740516662598] sec\n",
      "[3.629631996154785] sec\n",
      "[3.547180414199829] sec\n",
      "[3.682373046875] sec\n",
      "[3.4746298789978027] sec\n",
      "[3.677720785140991] sec\n",
      "[3.4508635997772217] sec\n",
      "4.25 s ± 945 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "simple_load_times = []\n",
    "start_time = time.time()\n",
    "for batch_idx, data in enumerate(loader):\n",
    "    inputs, labels = data\n",
    "    inputs = kornia_transform_ffcv(inputs.to(torch.float32))\n",
    "ffcv_time = time.time() - start_time\n",
    "simple_load_times.append(ffcv_time)\n",
    "print(str(simple_load_times) + ' sec') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 1.0\n",
    "albumentations_transform = A.Compose([\n",
    "    A.RandomCrop(16, 16, p=p),\n",
    "    A.ColorJitter(0.2, 0.2, 0.2, 0.125, p=p),\n",
    "    A.GaussianBlur(3, (0.1, 3.0), p=p),\n",
    "    A.Rotate((-10, 10), p=p),\n",
    "    A.HorizontalFlip(p=p),\n",
    "    A.VerticalFlip(p=p),\n",
    "    A.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5), p=p),\n",
    "    A.pytorch.ToTensorV2(),\n",
    "])\n",
    "kornia_transform = nn.Sequential(\n",
    "    K.augmentation.RandomCrop((16, 16), p=p),\n",
    "    K.augmentation.ColorJitter(0.2, 0.2, 0.2, 0.125, p=p),\n",
    "    K.augmentation.RandomGaussianBlur((3, 3), (0.1, 3.0), p=p),\n",
    "    K.augmentation.RandomRotation([-10, 10], p=p),\n",
    "    K.augmentation.RandomHorizontalFlip(p=p),\n",
    "    K.augmentation.RandomVerticalFlip(p=p),\n",
    "    K.augmentation.Normalize(torch.Tensor([0.5, 0.5, 0.5])*255, torch.Tensor([0.5, 0.5, 0.5])*255, p=p),\n",
    ")\n",
    "\n",
    "\n",
    "torchvision_transform = T.Compose([\n",
    "    T.RandomCrop([16, 16]),\n",
    "    T.ColorJitter(0.2, 0.2, 0.2, 0.125),  #Randomly change the brightness, contrast, saturation and hue of an image.\n",
    "    T.GaussianBlur(3, (0.1, 3.0)),\n",
    "    T.RandomRotation([-10, 10], T.InterpolationMode.BILINEAR),\n",
    "    T.RandomHorizontalFlip(p=p),\n",
    "    T.RandomVerticalFlip(p=p),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchivison - PIL loader\n",
    "\n",
    "root_path = '/home/aiteam/tykim/dataset/CIFAR-10-images/train'\n",
    "custom_ds = CustomDataset(root_path, loader_type='pil', transform=torchvision_transform)\n",
    "dataloader = DataLoader(custom_ds, batch_size=128, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.245321273803711] sec\n",
      "[8.256505012512207] sec\n",
      "[8.146782159805298] sec\n",
      "[8.263944387435913] sec\n",
      "[8.702878475189209] sec\n",
      "[8.481176137924194] sec\n",
      "[8.087376117706299] sec\n",
      "[8.03583288192749] sec\n",
      "[8.608634948730469] sec\n",
      "8.31 s ± 120 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "simple_load_times = []\n",
    "start_time = time.time()\n",
    "for image, label in dataloader:\n",
    "    image = image.cuda()\n",
    "    label = label.cuda()\n",
    "    pass\n",
    "pil_time = time.time() - start_time\n",
    "simple_load_times.append(pil_time)\n",
    "print(str(simple_load_times) + ' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jpeg4py + albumentation \n",
    "root_path = '/home/aiteam/tykim/dataset/CIFAR-10-images/train'\n",
    "custom_ds = CustomAlbDataset(root_path, loader_type='jpeg4py', transform=albumentations_transform)\n",
    "dataloader = DataLoader(custom_ds, batch_size=128, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.560781002044678] sec\n",
      "[3.701923131942749] sec\n",
      "[3.6266701221466064] sec\n",
      "[3.5955018997192383] sec\n",
      "[3.5598294734954834] sec\n",
      "[3.582918167114258] sec\n",
      "[3.7467784881591797] sec\n",
      "[3.6714329719543457] sec\n",
      "[3.7053630352020264] sec\n",
      "3.86 s ± 312 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "simple_load_times = []\n",
    "start_time = time.time()\n",
    "for image, label in dataloader:\n",
    "    image = image.cuda()\n",
    "    label = label.cuda()\n",
    "    pass\n",
    "jpeg4py_alb_time = time.time() - start_time\n",
    "simple_load_times.append(jpeg4py_alb_time)\n",
    "print(str(simple_load_times) + ' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jpeg4py + kornia-cpu\n",
    "root_path = '/home/aiteam/tykim/dataset/CIFAR-10-images/train'\n",
    "custom_ds = CustomKorDataset(root_path, loader_type='jpeg4py', transform=kornia_transform)\n",
    "dataloader = DataLoader(custom_ds, batch_size=128, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23.816331148147583] sec\n",
      "[23.018821239471436] sec\n",
      "[23.119860410690308] sec\n",
      "[26.715492725372314] sec\n",
      "[22.96969747543335] sec\n",
      "[23.019802808761597] sec\n",
      "[22.935904502868652] sec\n",
      "[23.335483074188232] sec\n",
      "[23.39503240585327] sec\n",
      "23.6 s ± 456 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "simple_load_times = []\n",
    "start_time = time.time()\n",
    "for image, label in dataloader:\n",
    "    image = image.cuda()\n",
    "    label = label.cuda()\n",
    "    pass\n",
    "jpeg4py_kornia_time = time.time() - start_time\n",
    "simple_load_times.append(jpeg4py_kornia_time)\n",
    "print(str(simple_load_times) + ' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DALI \n",
    "from nvidia.dali.pipeline import pipeline_def\n",
    "import nvidia.dali.types as types\n",
    "import nvidia.dali.fn as fn\n",
    "from nvidia.dali.plugin.pytorch import DALIGenericIterator\n",
    "\n",
    "root_path = '/home/aiteam/tykim/dataset/CIFAR-10-images/train'\n",
    "\n",
    "@pipeline_def(batch_size=128, num_threads=8, device_id=0)\n",
    "def get_dali_pipeline(data_dir, dali_cpu=False, crop=16):\n",
    "  dali_device = 'cpu' if dali_cpu else 'gpu'\n",
    "  decoder_device = 'cpu' if dali_cpu else 'mixed'\n",
    "  # w, h = int(crop * 120), int(crop * 400)\n",
    "  # imagebytes = w * h * 3 * 4\n",
    "  \n",
    "  img_files, labels = fn.readers.file(file_root=data_dir, random_shuffle=False, name=\"Reader\")\n",
    "  \n",
    "  # Load and Crop\n",
    "  # 이미지 사이즈 힌트\n",
    "  preallocate_width_hint = 32 if decoder_device == 'mixed' else 0\n",
    "  preallocate_height_hint = 32 if decoder_device == 'mixed' else 0\n",
    "  \n",
    "  # images = fn.decoders.image(img_files, device=\"mixed\")\n",
    "  # Decode and Random Crop\n",
    "  images = fn.decoders.image_random_crop(img_files, device=decoder_device, preallocate_width_hint=preallocate_width_hint,\n",
    "                                         preallocate_height_hint=preallocate_height_hint,\n",
    "                                         output_type=types.RGB, random_aspect_ratio=[0.8, 1.25], random_area=[0.1, 1.0])\n",
    "  \n",
    "  # Resize\n",
    "  images = fn.resize(images,device=dali_device,resize_x=crop, resize_y=crop,interp_type=types.INTERP_TRIANGULAR)\n",
    "  # Jitter \n",
    "  images = fn.color_twist(images, brightness=0.2, contrast=0.2, saturation=0.2, hue=0.125)\n",
    "  # GaussianBlur\n",
    "  images = fn.gaussian_blur(images, device = dali_device, # bytes_per_sample_hint = imagebytes, \n",
    "                   sigma = fn.random.uniform(range = (0.1, 3.0)), window_size = 3)\n",
    "  # # Random Rotation\n",
    "  images = fn.rotate(images, device=dali_device, angle=fn.random.uniform(range=(-10, 10)), keep_size=True) \n",
    "  # Horizontal F\n",
    "  images = fn.flip(images, device=dali_device, horizontal=1)\n",
    "  # Vertical F\n",
    "  images = fn.flip(images, device=dali_device, horizontal=0)\n",
    "  # Normalization\n",
    "  images = fn.crop_mirror_normalize(images, device=dali_device,\n",
    "                                    dtype=types.FLOAT,\n",
    "                                    mean = [0.5*255, 0.5*255, 0.5*255],\n",
    "                                    std = [0.5*255, 0.5*255, 0.5*255])\n",
    "  return images, labels.gpu()\n",
    "\n",
    "pipe = get_dali_pipeline(data_dir=root_path)\n",
    "pipe.build()\n",
    "\n",
    "dataloader = DALIGenericIterator(pipe, ['data', 'label'],reader_name='Reader')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.595245599746704] sec\n",
      "[1.5693223476409912] sec\n",
      "[1.5602564811706543] sec\n",
      "[1.576174020767212] sec\n",
      "[1.5647480487823486] sec\n",
      "[1.5459952354431152] sec\n",
      "[1.4748666286468506] sec\n",
      "[1.4407780170440674] sec\n",
      "[1.4309241771697998] sec\n",
      "1.53 s ± 56.6 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "simple_load_times = []\n",
    "start_time = time.time()\n",
    "for i, data in enumerate(dataloader):\n",
    "  x, y = data[0]['data'], data[0]['label']  \n",
    "\n",
    "dali_time = time.time() - start_time\n",
    "simple_load_times.append(dali_time)\n",
    "print(str(simple_load_times) + ' sec') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ffcv.writer import DatasetWriter\n",
    "from ffcv.fields import IntField, RGBImageField\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from ffcv.fields.decoders import IntDecoder, SimpleRGBImageDecoder, RandomResizedCropRGBImageDecoder\n",
    "from ffcv.loader import Loader, OrderOption\n",
    "from ffcv.transforms import ToDevice, ToTensor, ToTorchImage, NormalizeImage, RandomHorizontalFlip\n",
    "\n",
    "\n",
    "\n",
    "beton_path = '/home/aiteam/tykim/scratch/data_loaders/cifar10_io_test.beton'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random resized crop\n",
    "decoder = RandomResizedCropRGBImageDecoder(output_size=(16, 16))# SimpleRGBImageDecoder()\n",
    "\n",
    "# Data decoding and augmentation\n",
    "image_pipeline = [decoder,  RandomHorizontalFlip(flip_prob=1.0),\n",
    "                  ToTensor(), ToTorchImage(), ToDevice('cuda:0', non_blocking=True),]\n",
    "                  #NormalizeImage(mean, std)] #Cutout(),\n",
    "label_pipeline = [IntDecoder(), ToTensor(), ToDevice('cuda:0')]\n",
    "\n",
    "# Pipeline for each data field\n",
    "pipelines = {\n",
    "    'image': image_pipeline,\n",
    "    'label': label_pipeline\n",
    "}\n",
    "\n",
    "# Replaces PyTorch data loader (`torch.utils.data.Dataloader`)\n",
    "loader = Loader(beton_path, batch_size=128, num_workers=8,\n",
    "                order=OrderOption.RANDOM, pipelines=pipelines, os_cache=True)\n",
    "\n",
    "\n",
    "kornia_transform_ffcv = nn.Sequential(\n",
    "    K.augmentation.ColorJitter(0.2, 0.2, 0.2, 0.125, p=1.0),\n",
    "    K.augmentation.RandomGaussianBlur((3, 3), (0.1, 3.0), p=1.0),\n",
    "    K.augmentation.RandomRotation([-10, 10], p=1.0),\n",
    "    K.augmentation.RandomVerticalFlip(p=1.0),\n",
    "    K.augmentation.Normalize(torch.tensor([0.5*255, 0.5*255, 0.5*255]),\n",
    "                             torch.tensor([0.5*255, 0.5*255, 0.5*255]), p=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.300191879272461] sec\n",
      "[4.742574214935303] sec\n",
      "[4.702749729156494] sec\n",
      "[4.74065637588501] sec\n",
      "[4.718742847442627] sec\n",
      "[4.7166428565979] sec\n",
      "[4.7094902992248535] sec\n",
      "[4.333574533462524] sec\n",
      "[3.7038724422454834] sec\n",
      "5.07 s ± 853 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "simple_load_times = []\n",
    "start_time = time.time()\n",
    "for batch_idx, data in enumerate(loader):\n",
    "    inputs, labels = data\n",
    "    inputs = kornia_transform_ffcv(inputs.to(torch.float32))\n",
    "ffcv_time = time.time() - start_time\n",
    "simple_load_times.append(ffcv_time)\n",
    "print(str(simple_load_times) + ' sec') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('loader': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a254999b829cf7a75923305dbce36972a67b91fdc16edd342b076b25e04d6382"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
