{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from set_loader import CustomDataset\n",
    "import jpeg4py as jpeg\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AFHQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIL Loader\n",
    "root_path = '/home/aiteam/tykim/dataset/afhq/train'\n",
    "custom_ds = CustomDataset(root_path, loader_type='pil')\n",
    "dataloader = DataLoader(custom_ds, batch_size=128, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18.762083530426025] sec\n",
      "[18.24456214904785] sec\n",
      "[17.425167322158813] sec\n",
      "[18.613457441329956] sec\n",
      "[19.203899145126343] sec\n",
      "[19.258994817733765] sec\n",
      "[19.374570608139038] sec\n",
      "[18.847532033920288] sec\n",
      "[19.108444690704346] sec\n",
      "18.8 s ± 437 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "simple_load_times = []\n",
    "start_time = time.time()\n",
    "for image, label in dataloader:\n",
    "    image = image.cuda()\n",
    "    label = label.cuda()\n",
    "    pass\n",
    "pil_time = time.time() - start_time\n",
    "simple_load_times.append(pil_time)\n",
    "print(str(simple_load_times) + ' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPEN CV Loader\n",
    "root_path = '/home/aiteam/tykim/dataset/afhq/train'\n",
    "custom_ds = CustomDataset(root_path, loader_type='opencv')\n",
    "dataloader = DataLoader(custom_ds, batch_size=128, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.810119867324829] sec\n",
      "[7.763317346572876] sec\n",
      "[7.54777193069458] sec\n",
      "[7.822279214859009] sec\n",
      "[7.724693536758423] sec\n",
      "[7.8466784954071045] sec\n",
      "[7.711875915527344] sec\n",
      "[7.677571773529053] sec\n",
      "[7.6445276737213135] sec\n",
      "7.73 s ± 51.1 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "simple_load_times = []\n",
    "start_time = time.time()\n",
    "for image, label in dataloader:\n",
    "    image = image.cuda()\n",
    "    label = label.cuda()\n",
    "    pass\n",
    "opencv_time = time.time() - start_time\n",
    "simple_load_times.append(opencv_time)\n",
    "print(str(simple_load_times) + ' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jpeg4Py Loader\n",
    "root_path = '/home/aiteam/tykim/dataset/afhq/train'\n",
    "custom_ds = CustomDataset(root_path, loader_type='jpeg4py')\n",
    "dataloader = DataLoader(custom_ds, batch_size=128, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.72104024887085] sec\n",
      "[5.583805322647095] sec\n",
      "[5.445183515548706] sec\n",
      "[5.339044809341431] sec\n",
      "[5.4290385246276855] sec\n",
      "[5.507980823516846] sec\n",
      "[5.217567682266235] sec\n",
      "[5.513427019119263] sec\n",
      "[5.363497018814087] sec\n",
      "5.46 s ± 92.1 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "simple_load_times = []\n",
    "start_time = time.time()\n",
    "for image, label in dataloader:\n",
    "    image = image.cuda()\n",
    "    label = label.cuda()\n",
    "    pass\n",
    "jpeg4py_time = time.time() - start_time\n",
    "simple_load_times.append(jpeg4py_time)\n",
    "print(str(simple_load_times) + ' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvidia.dali.pipeline import pipeline_def\n",
    "import nvidia.dali.types as types\n",
    "import nvidia.dali.fn as fn\n",
    "from nvidia.dali.plugin.pytorch import DALIGenericIterator\n",
    "\n",
    "root_path = '/home/aiteam/tykim/dataset/afhq/train'\n",
    "\n",
    "@pipeline_def(batch_size=128, num_threads=8, device_id=0)\n",
    "def get_dali_pipeline(data_dir):\n",
    "  img_files, labels = fn.readers.file(file_root=data_dir, random_shuffle=False, name=\"Reader\")\n",
    "  images = fn.decoders.image(img_files, device=\"mixed\")\n",
    "  \n",
    "  return images, labels.gpu()\n",
    "\n",
    "pipe = get_dali_pipeline(data_dir=root_path)\n",
    "pipe.build()\n",
    "\n",
    "dataloader = DALIGenericIterator(pipe, ['data', 'label'],reader_name='Reader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.4376187324523926] sec\n",
      "[1.3231616020202637] sec\n",
      "[1.3179664611816406] sec\n",
      "[1.354482650756836] sec\n",
      "[1.3438947200775146] sec\n",
      "[1.3326356410980225] sec\n",
      "[1.3353204727172852] sec\n",
      "[1.3344662189483643] sec\n",
      "[1.4105403423309326] sec\n",
      "1.35 s ± 7.67 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "simple_load_times = []\n",
    "start_time = time.time()\n",
    "for i, data in enumerate(dataloader):\n",
    "  x, y = data[0]['data'], data[0]['label']  \n",
    "\n",
    "dali_time = time.time() - start_time\n",
    "simple_load_times.append(dali_time)\n",
    "print(str(simple_load_times) + ' sec') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFCV - JPEG 100 % quality\n",
    "\n",
    "from ffcv.writer import DatasetWriter\n",
    "from ffcv.fields import IntField, RGBImageField\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from ffcv.fields.decoders import IntDecoder, SimpleRGBImageDecoder\n",
    "from ffcv.loader import Loader, OrderOption\n",
    "from ffcv.transforms import ToDevice, ToTensor, ToTorchImage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14630/14630 [00:21<00:00, 696.44it/s] \n"
     ]
    }
   ],
   "source": [
    "# Preparation\n",
    "my_dataset = ImageFolder(root='/home/aiteam/tykim/dataset/afhq/train')\n",
    "write_path = '/home/aiteam/tykim/scratch/data_loaders/afhq_io_test.beton'\n",
    "\n",
    "# Pass a type for each data field\n",
    "writer = DatasetWriter(write_path, {\n",
    "    'image': RGBImageField(jpeg_quality=100),\n",
    "    'label': IntField()\n",
    "})\n",
    "\n",
    "# Write dataset\n",
    "writer.from_indexed_dataset(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random resized crop\n",
    "decoder = SimpleRGBImageDecoder()\n",
    "\n",
    "# Data decoding and augmentation\n",
    "image_pipeline = [decoder,  ToTensor(), ToTorchImage(), ToDevice('cuda:0', non_blocking=True)] #Cutout(),\n",
    "label_pipeline = [IntDecoder(), ToTensor(), ToDevice('cuda:0')]\n",
    "\n",
    "# Pipeline for each data field\n",
    "pipelines = {\n",
    "    'image': image_pipeline,\n",
    "    'label': label_pipeline\n",
    "}\n",
    "\n",
    "# Replaces PyTorch data loader (`torch.utils.data.Dataloader`)\n",
    "loader = Loader(write_path, batch_size=128, num_workers=8,\n",
    "                order=OrderOption.RANDOM, pipelines=pipelines, os_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.9811444282531738] sec\n",
      "[1.1470427513122559] sec\n",
      "[1.1128733158111572] sec\n",
      "[0.8895688056945801] sec\n",
      "[0.9101715087890625] sec\n",
      "[0.9381265640258789] sec\n",
      "[0.9251284599304199] sec\n",
      "[0.9449906349182129] sec\n",
      "[0.918032169342041] sec\n",
      "1.09 s ± 232 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "simple_load_times = []\n",
    "start_time = time.time()\n",
    "for batch_idx, data in enumerate(loader):\n",
    "    inputs, labels = data\n",
    "    \n",
    "ffcv_time = time.time() - start_time\n",
    "simple_load_times.append(ffcv_time)\n",
    "print(str(simple_load_times) + ' sec') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quasi_random\n",
    "decoder = SimpleRGBImageDecoder()\n",
    "\n",
    "# Data decoding and augmentation\n",
    "image_pipeline = [decoder,  ToTensor(), ToTorchImage(), ToDevice('cuda:0', non_blocking=True)] #Cutout(),\n",
    "label_pipeline = [IntDecoder(), ToTensor(), ToDevice('cuda:0')]\n",
    "\n",
    "# Pipeline for each data field\n",
    "pipelines = {\n",
    "    'image': image_pipeline,\n",
    "    'label': label_pipeline\n",
    "}\n",
    "\n",
    "# Replaces PyTorch data loader (`torch.utils.data.Dataloader`)\n",
    "loader = Loader(write_path, batch_size=128, num_workers=8,\n",
    "                order=OrderOption.QUASI_RANDOM, pipelines=pipelines, os_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.7662463188171387] sec\n",
      "[0.9466965198516846] sec\n",
      "[0.971419095993042] sec\n",
      "[0.9264469146728516] sec\n",
      "[0.9306745529174805] sec\n",
      "[0.9450130462646484] sec\n",
      "[0.9147017002105713] sec\n",
      "[0.9315376281738281] sec\n",
      "[0.9097979068756104] sec\n",
      "1.03 s ± 142 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "simple_load_times = []\n",
    "start_time = time.time()\n",
    "for batch_idx, data in enumerate(loader):\n",
    "    inputs, labels = data\n",
    "    \n",
    "ffcv_time = time.time() - start_time\n",
    "simple_load_times.append(ffcv_time)\n",
    "print(str(simple_load_times) + ' sec') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIL Loader\n",
    "root_path = '/home/aiteam/tykim/dataset/CIFAR-10-images/train'\n",
    "custom_ds = CustomDataset(root_path, loader_type='pil')\n",
    "dataloader = DataLoader(custom_ds, batch_size=128, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.300985813140869] sec\n",
      "[1.7530553340911865] sec\n",
      "[2.084369659423828] sec\n",
      "[1.956310510635376] sec\n",
      "[1.895453691482544] sec\n",
      "[1.8113484382629395] sec\n",
      "[2.076040744781494] sec\n",
      "[1.9186503887176514] sec\n",
      "[2.023421287536621] sec\n",
      "2.09 s ± 210 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "simple_load_times = []\n",
    "start_time = time.time()\n",
    "for image, label in dataloader:\n",
    "    image = image.cuda()\n",
    "    label = label.cuda()\n",
    "    pass\n",
    "pil_time = time.time() - start_time\n",
    "simple_load_times.append(pil_time)\n",
    "print(str(simple_load_times) + ' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPEN CV Loader\n",
    "root_path = '/home/aiteam/tykim/dataset/CIFAR-10-images/train'\n",
    "custom_ds = CustomDataset(root_path, loader_type='opencv')\n",
    "dataloader = DataLoader(custom_ds, batch_size=128, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8447706699371338] sec\n",
      "[0.8297159671783447] sec\n",
      "[0.782383918762207] sec\n",
      "[0.7501564025878906] sec\n",
      "[0.777930498123169] sec\n",
      "[0.7334840297698975] sec\n",
      "[0.6861250400543213] sec\n",
      "[0.8113012313842773] sec\n",
      "[0.7088854312896729] sec\n",
      "770 ms ± 35.8 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "simple_load_times = []\n",
    "start_time = time.time()\n",
    "for image, label in dataloader:\n",
    "    image = image.cuda()\n",
    "    label = label.cuda()\n",
    "    pass\n",
    "opencv_time = time.time() - start_time\n",
    "simple_load_times.append(opencv_time)\n",
    "print(str(simple_load_times) + ' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jpeg4Py Loader\n",
    "root_path = '/home/aiteam/tykim/dataset/CIFAR-10-images/train'\n",
    "custom_ds = CustomDataset(root_path, loader_type='jpeg4py')\n",
    "dataloader = DataLoader(custom_ds, batch_size=128, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9442241191864014] sec\n",
      "[0.9938108921051025] sec\n",
      "[0.9856014251708984] sec\n",
      "[0.9854307174682617] sec\n",
      "[0.9906682968139648] sec\n",
      "[0.9095518589019775] sec\n",
      "[1.0330533981323242] sec\n",
      "[0.946082592010498] sec\n",
      "[0.901226282119751] sec\n",
      "966 ms ± 6.41 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "simple_load_times = []\n",
    "start_time = time.time()\n",
    "for image, label in dataloader:\n",
    "    image = image.cuda()\n",
    "    label = label.cuda()\n",
    "    pass\n",
    "jpeg4py_time = time.time() - start_time\n",
    "simple_load_times.append(jpeg4py_time)\n",
    "print(str(simple_load_times) + ' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DALI\n",
    "from nvidia.dali.pipeline import pipeline_def\n",
    "import nvidia.dali.types as types\n",
    "import nvidia.dali.fn as fn\n",
    "from nvidia.dali.plugin.pytorch import DALIGenericIterator\n",
    "\n",
    "root_path = '/home/aiteam/tykim/dataset/CIFAR-10-images/train'\n",
    "\n",
    "\n",
    "@pipeline_def(batch_size=128, num_threads=8, device_id=0)\n",
    "def get_dali_pipeline(data_dir):\n",
    "  img_files, labels = fn.readers.file(file_root=data_dir, random_shuffle=False, name=\"Reader\")\n",
    "  images = fn.decoders.image(img_files, device=\"mixed\")\n",
    "  \n",
    "  return images, labels.gpu()\n",
    "\n",
    "pipe = get_dali_pipeline(data_dir=root_path)\n",
    "pipe.build()\n",
    "\n",
    "dataloader = DALIGenericIterator(pipe, ['data', 'label'],reader_name='Reader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8147809505462646] sec\n",
      "[0.7482140064239502] sec\n",
      "[0.668778657913208] sec\n",
      "[0.7292904853820801] sec\n",
      "[0.676008939743042] sec\n",
      "[0.6448142528533936] sec\n",
      "[0.6547183990478516] sec\n",
      "[0.6652204990386963] sec\n",
      "[0.6618211269378662] sec\n",
      "696 ms ± 35.2 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "simple_load_times = []\n",
    "start_time = time.time()\n",
    "for i, data in enumerate(dataloader):\n",
    "  x, y = data[0]['data'], data[0]['label']  \n",
    "\n",
    "dali_time = time.time() - start_time\n",
    "simple_load_times.append(dali_time)\n",
    "print(str(simple_load_times) + ' sec') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFCV\n",
    "\n",
    "from ffcv.writer import DatasetWriter\n",
    "from ffcv.fields import IntField, RGBImageField\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from ffcv.fields.decoders import IntDecoder, SimpleRGBImageDecoder\n",
    "from ffcv.loader import Loader, OrderOption\n",
    "from ffcv.transforms import ToDevice, ToTensor, ToTorchImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:00<00:00, 498219.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# Preparation\n",
    "\n",
    "my_dataset = ImageFolder(root='/home/aiteam/tykim/dataset/CIFAR-10-images/train')\n",
    "write_path = '/home/aiteam/tykim/scratch/data_loaders/cifar10_io_test.beton'\n",
    "\n",
    "# Pass a type for each data field\n",
    "writer = DatasetWriter(write_path, {\n",
    "    'image': RGBImageField(jpeg_quality=100),\n",
    "    'label': IntField()\n",
    "})\n",
    "\n",
    "# Write dataset\n",
    "writer.from_indexed_dataset(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random resized crop\n",
    "decoder = SimpleRGBImageDecoder()\n",
    "\n",
    "# Data decoding and augmentation\n",
    "image_pipeline = [decoder,  ToTensor(), ToTorchImage(), ToDevice('cuda:0', non_blocking=True)] #Cutout(),\n",
    "label_pipeline = [IntDecoder(), ToTensor(), ToDevice('cuda:0')]\n",
    "\n",
    "# Pipeline for each data field\n",
    "pipelines = {\n",
    "    'image': image_pipeline,\n",
    "    'label': label_pipeline\n",
    "}\n",
    "\n",
    "# Replaces PyTorch data loader (`torch.utils.data.Dataloader`)\n",
    "loader = Loader(write_path, batch_size=128, num_workers=8,\n",
    "                order=OrderOption.RANDOM, pipelines=pipelines, os_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0405628681182861] sec\n",
      "[0.19046449661254883] sec\n",
      "[0.2178652286529541] sec\n",
      "[0.21071386337280273] sec\n",
      "[0.21244049072265625] sec\n",
      "[0.22309231758117676] sec\n",
      "[0.22395992279052734] sec\n",
      "[0.22606253623962402] sec\n",
      "[0.22167515754699707] sec\n",
      "308 ms ± 124 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "simple_load_times = []\n",
    "start_time = time.time()\n",
    "for batch_idx, data in enumerate(loader):\n",
    "    inputs, labels = data\n",
    "    \n",
    "ffcv_time = time.time() - start_time\n",
    "simple_load_times.append(ffcv_time)\n",
    "print(str(simple_load_times) + ' sec') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random resized crop\n",
    "decoder = SimpleRGBImageDecoder()\n",
    "\n",
    "# Data decoding and augmentation\n",
    "image_pipeline = [decoder,  ToTensor(), ToTorchImage(), ToDevice('cuda:0', non_blocking=True)] #Cutout(),\n",
    "label_pipeline = [IntDecoder(), ToTensor(), ToDevice('cuda:0')]\n",
    "\n",
    "# Pipeline for each data field\n",
    "pipelines = {\n",
    "    'image': image_pipeline,\n",
    "    'label': label_pipeline\n",
    "}\n",
    "write_path = '/home/aiteam/tykim/scratch/data_loaders/cifar10_io_test.beton'\n",
    "# Replaces PyTorch data loader (`torch.utils.data.Dataloader`)\n",
    "loader = Loader(write_path, batch_size=128, num_workers=8,\n",
    "                order=OrderOption.QUASI_RANDOM, pipelines=pipelines, os_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.009735345840454] sec\n",
      "[0.1959528923034668] sec\n",
      "[0.21576571464538574] sec\n",
      "[0.23236322402954102] sec\n",
      "[0.22238373756408691] sec\n",
      "[0.2182614803314209] sec\n",
      "[0.217071533203125] sec\n",
      "[0.23358869552612305] sec\n",
      "[0.2304394245147705] sec\n",
      "308 ms ± 117 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "simple_load_times = []\n",
    "start_time = time.time()\n",
    "for batch_idx, data in enumerate(loader):\n",
    "    inputs, labels = data\n",
    "    \n",
    "ffcv_time = time.time() - start_time\n",
    "simple_load_times.append(ffcv_time)\n",
    "print(str(simple_load_times) + ' sec') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## 최종 결과 ##########\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "left = np.array([1, 2, 3, 4])\n",
    "height = np.array([71, 41.5, 26.2, 8.1])\n",
    "label = [\"OpenCV\\n+\\nAlbumentations\", \"jpeg4py\\n+\\nAlbumentations\", \"jpeg4py\\n+\\nKornia\", \"NVIDIA DALI\\n+\\nKornia\"]\n",
    "plt.bar(left, height, tick_label=label, align=\"center\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('loader')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a254999b829cf7a75923305dbce36972a67b91fdc16edd342b076b25e04d6382"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
